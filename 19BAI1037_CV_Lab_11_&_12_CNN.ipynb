{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCO0ucF9ezFp"
   },
   "source": [
    "# Lab 11 & 12 :  Image Classification using CNN\n",
    "#### Name:- Sruthi Nayagi \n",
    "#### Reg.no:- 19BAI1037 \n",
    "#### Subject:- Computer Vision in Healthcare Application (CSE4038) \n",
    "#### Faculty-In-Charge:- Dr.BALASUNDARAM A\n",
    "#### Lab Slot:- L27+L28 \n",
    "#### Date of Submission:- 13/04/2022\n",
    "#### Dataset Used:- Chest_xrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjMFgoP5fL91"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dHX-UGzxfPq-"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDAg3RkrfH-G"
   },
   "source": [
    "## Building the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "piKAs1C7exHV"
   },
   "outputs": [],
   "source": [
    "classifier= Sequential() # Initialise the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A6eQqzQFfHMP"
   },
   "outputs": [],
   "source": [
    "# 1st Convoltional layer to get feature maps using feature detector\n",
    "classifier.add(Convolution2D(filters=32, # output feature maps\n",
    "                             kernel_size=(3,3), # matrix size for feature detector\n",
    "                             input_shape=(64, 64, 3), # input image shape, 3 is for rgb coloured image with 128*128 px\n",
    "                             kernel_initializer='he_uniform', # weights distriution\n",
    "                             activation='relu')) # activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cW6JTnXKfmha"
   },
   "outputs": [],
   "source": [
    "# 2nd Pooling layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9j0OGNfdfoWF"
   },
   "outputs": [],
   "source": [
    "#2nd convolutional and pooling layer.\n",
    "classifier.add(Convolution2D(filters=32,\n",
    "                             kernel_size=(3,3), \n",
    "                             kernel_initializer='he_uniform', \n",
    "                             activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jzEC1ty5fp4o"
   },
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Zm1RyyjpfrcA"
   },
   "outputs": [],
   "source": [
    "#Step 4 full connection in which input we have from flattening\n",
    "\n",
    "classifier.add(Dense(units=128,kernel_initializer='glorot_uniform', activation='relu')) \n",
    "#step 5 output layer\n",
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMcLvhnEfw79"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ek26dgiyfyxb"
   },
   "outputs": [],
   "source": [
    "#applying all the transformation we want to apply to training data set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "--e40fgOf0Ga"
   },
   "outputs": [],
   "source": [
    "#Rescaling the test data set images to use for validation.\n",
    "test_datagen= ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GjjY70SYf142",
    "outputId": "248ae61c-8176-48f8-d7cc-f4aeeeb5a167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Getting My training data ready for validation, so it will read all the data with the px size we gave.\n",
    "\n",
    "training_set= train_datagen.flow_from_directory(directory= '/content/drive/MyDrive/chest_xray/train',\n",
    "                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n",
    "                                               batch_size=128,\n",
    "                                               class_mode='binary' # for 2 class binary \n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd9FcG3uf7-y",
    "outputId": "f9521432-a90b-4c72-e3a7-34e0c72cfe5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Getting My test data ready for validation, so it will read all the data with the px size we gave.\n",
    "\n",
    "test_set= test_datagen.flow_from_directory(directory= '/content/drive/MyDrive/chest_xray/test',\n",
    "                                               target_size=(64,64), # As we choose 64*64 for our convolution model\n",
    "                                               batch_size=128,\n",
    "                                               class_mode='binary' # for 2 class binary\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgSbVFh74cJQ"
   },
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3EMx0wYf-Yj",
    "outputId": "276106d6-c066-4bf9-a15e-7caf0e85548c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 1.1182 - accuracy: 0.6334 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "9/9 [==============================] - 634s 72s/step - loss: 1.1182 - accuracy: 0.6334 - val_loss: 0.8685 - val_accuracy: 0.6250\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 96s 11s/step - loss: 0.5569 - accuracy: 0.7496\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 96s 10s/step - loss: 0.4635 - accuracy: 0.7862\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 94s 10s/step - loss: 0.3402 - accuracy: 0.8606\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 96s 11s/step - loss: 0.2871 - accuracy: 0.8740\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 95s 10s/step - loss: 0.2771 - accuracy: 0.8821\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 97s 10s/step - loss: 0.2345 - accuracy: 0.8986\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 98s 10s/step - loss: 0.2210 - accuracy: 0.9116\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 98s 11s/step - loss: 0.2175 - accuracy: 0.9122\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 95s 10s/step - loss: 0.2052 - accuracy: 0.9156\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(training_set,\n",
    "                        batch_size=128,# Data in training set\n",
    "                        epochs=10,\n",
    "                        verbose=1, \n",
    "                        validation_data=test_set, \n",
    "                        validation_steps=624 # no of data point for validation\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SsplaFlqUJd",
    "outputId": "eac23db9-880a-4bf2-b092-8ad03b91aae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30975332856178284\n",
      "Test accuracy: 0.8782051205635071\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(test_set, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCrtSwd52pdD"
   },
   "source": [
    "# Inference:\n",
    "The training accuracy of the model is 87% and the training loss is 30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8HANU8okaKc"
   },
   "source": [
    "## Testing the Model\n",
    "By making new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YrLTmYAEgK0h",
    "outputId": "5f22339f-9b19-45db-ca7f-2324bba1c77c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th given image is predicted as: NORMAL\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('/content/drive/MyDrive/chest_xray/val/NORMAL/NORMAL2-IM-1427-0001.jpeg', target_size = (64, 64))\n",
    "# Loading the image and converting the pixels into array whcih will be used as input to predict.\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'NORMAL'\n",
    "else:\n",
    "    prediction = 'PNEUNOMIA'\n",
    "print(\"Th given image is predicted as:\",prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YEAwcPH2dAg"
   },
   "source": [
    "# Conclusion:\n",
    "Thus, this model has predicted that the given image is NORMAL correctly."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " 19BAI1037_CV Lab 11 & 12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
